{"allContent":{"docusaurus-plugin-css-cascade-layers":{},"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","isLast":true,"routePriority":-1,"sidebarFilePath":"D:\\piaic_hackathon\\my-book\\sidebars.ts","contentPath":"D:\\piaic_hackathon\\my-book\\docs","docs":[{"id":"assessments","title":"Assessments","description":"This section details the various assessment components designed to evaluate your understanding and practical application of the course material. These assessments are structured to reinforce learning and provide opportunities to demonstrate proficiency in key areas of Physical AI and humanoid robotics.","source":"@site/docs/assessments.md","sourceDirName":".","slug":"/assessments","permalink":"/docs/assessments","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Weekly Breakdown","permalink":"/docs/weekly-breakdown"},"next":{"title":"Hardware Requirements for Physical AI & Humanoid Robotics","permalink":"/docs/hardware-requirements/"}},{"id":"digital-twin/digital-twin-overview","title":"The Digital Twin (Gazebo & Unity) Overview","description":"Explore the concept of a Digital Twin in robotics, focusing on its role in creating virtual replicas of physical systems for safe and efficient development. This module utilizes powerful simulation platforms like Gazebo and Unity to build, test, and refine humanoid robot behaviors in a controlled virtual environment.","source":"@site/docs/digital-twin/digital-twin-overview.md","sourceDirName":"digital-twin","slug":"/digital-twin/digital-twin-overview","permalink":"/docs/digital-twin/digital-twin-overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"The Digital Twin (Gazebo & Unity) Overview"},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Core Concepts and Fundamentals","permalink":"/docs/ros-2-fundamentals/ros-2-concepts"},"next":{"title":"Robot Simulation with Gazebo and Unity","permalink":"/docs/digital-twin/simulation-with-gazebo"}},{"id":"digital-twin/simulation-with-gazebo","title":"Robot Simulation with Gazebo and Unity","description":"Gazebo is an open-source 3D robot simulator known for its robust physics engine and tight ROS integration, ideal for validating robotic algorithms. Unity, a powerful game engine, offers advanced rendering and a growing robotics ecosystem for high-fidelity sensor simulation and AI training. This section explores the practical setup and utilization of both Gazebo and Unity for designing, testing, and refining robotic systems in virtual environments.","source":"@site/docs/digital-twin/simulation-with-gazebo.md","sourceDirName":"digital-twin","slug":"/digital-twin/simulation-with-gazebo","permalink":"/docs/digital-twin/simulation-with-gazebo","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Robot Simulation with Gazebo and Unity"},"sidebar":"tutorialSidebar","previous":{"title":"The Digital Twin (Gazebo & Unity) Overview","permalink":"/docs/digital-twin/digital-twin-overview"},"next":{"title":"The AI-Robot Brain (NVIDIA Isaac™) Overview","permalink":"/docs/nvidia-isaac-platform/isaac-overview"}},{"id":"hardware-requirements/index","title":"Hardware Requirements for Physical AI & Humanoid Robotics","description":"This section details the essential hardware components and configurations required to build a capable Physical AI laboratory. It covers everything from high-performance workstations for simulation and AI training to specialized edge computing kits and various robot platforms, ensuring you have the right tools for hands-on development.","source":"@site/docs/hardware-requirements/index.md","sourceDirName":"hardware-requirements","slug":"/hardware-requirements/","permalink":"/docs/hardware-requirements/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Hardware Requirements for Physical AI & Humanoid Robotics"},"sidebar":"tutorialSidebar","previous":{"title":"Assessments","permalink":"/docs/assessments"},"next":{"title":"Hardware Requirements for Physical AI & Humanoid Robotics","permalink":"/docs/hardware-requirements/"}},{"id":"introduction/index","title":"Introduction: The Rise of Physical AI and Humanoid Robotics","description":"The Physical World Is About to Change","source":"@site/docs/introduction/index.md","sourceDirName":"introduction","slug":"/introduction/","permalink":"/docs/introduction/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Introduction: The Rise of Physical AI and Humanoid Robotics"},"sidebar":"tutorialSidebar","previous":{"title":"Preface: Welcome to the Era of Physical AI","permalink":"/docs/preface"},"next":{"title":"The Robotic Nervous System (ROS 2) Overview","permalink":"/docs/ros-2-fundamentals/ros-2-overview"}},{"id":"nvidia-isaac-platform/isaac-overview","title":"The AI-Robot Brain (NVIDIA Isaac™) Overview","description":"Dive into the NVIDIA Isaac platform, a comprehensive suite of tools, software, and hardware designed to accelerate AI-powered robotics. This module covers advanced perception, simulation, and autonomous capabilities, leveraging Isaac Sim and Isaac ROS to bring intelligent Physical AI applications to life.","source":"@site/docs/nvidia-isaac-platform/isaac-overview.md","sourceDirName":"nvidia-isaac-platform","slug":"/nvidia-isaac-platform/isaac-overview","permalink":"/docs/nvidia-isaac-platform/isaac-overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"The AI-Robot Brain (NVIDIA Isaac™) Overview"},"sidebar":"tutorialSidebar","previous":{"title":"Robot Simulation with Gazebo and Unity","permalink":"/docs/digital-twin/simulation-with-gazebo"},"next":{"title":"NVIDIA Isaac Platform for Perception and Training","permalink":"/docs/nvidia-isaac-platform/isaac-perception-training"}},{"id":"nvidia-isaac-platform/isaac-perception-training","title":"NVIDIA Isaac Platform for Perception and Training","description":"NVIDIA Isaac platform provides comprehensive tools for developing, simulating, and deploying AI-powered robots, with a strong focus on perception and training. This section delves into how Isaac ROS accelerates vision pipelines for tasks like object detection and pose estimation, and how Isaac Sim enables synthetic data generation in simulation environments. These capabilities are crucial for efficiently training robust AI models for humanoid robotics, bridging the gap between virtual experimentation and real-world deployment.","source":"@site/docs/nvidia-isaac-platform/isaac-perception-training.md","sourceDirName":"nvidia-isaac-platform","slug":"/nvidia-isaac-platform/isaac-perception-training","permalink":"/docs/nvidia-isaac-platform/isaac-perception-training","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"NVIDIA Isaac Platform for Perception and Training"},"sidebar":"tutorialSidebar","previous":{"title":"The AI-Robot Brain (NVIDIA Isaac™) Overview","permalink":"/docs/nvidia-isaac-platform/isaac-overview"},"next":{"title":"Vision-Language-Action (VLA) Overview","permalink":"/docs/vla-and-conversational-robotics/vla-overview"}},{"id":"preface","title":"Preface: Welcome to the Era of Physical AI","description":"The Journey from Digital to Physical Intelligence","source":"@site/docs/preface.md","sourceDirName":".","slug":"/preface","permalink":"/docs/preface","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"title":"Preface: Welcome to the Era of Physical AI"},"sidebar":"tutorialSidebar","next":{"title":"Introduction","permalink":"/docs/introduction/"}},{"id":"ros-2-fundamentals/ros-2-concepts","title":"ROS 2 Core Concepts and Fundamentals","description":"ROS 2 (Robot Operating System 2) is a flexible framework providing tools, libraries, and conventions for building complex robotic applications. This section dives into its foundational elements: nodes, topics, services, actions, and parameters, which enable distributed, real-time, and secure communication among various components of a robotic system. Understanding these core concepts is essential for developing robust and scalable Physical AI solutions.","source":"@site/docs/ros-2-fundamentals/ros-2-concepts.md","sourceDirName":"ros-2-fundamentals","slug":"/ros-2-fundamentals/ros-2-concepts","permalink":"/docs/ros-2-fundamentals/ros-2-concepts","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"ROS 2 Core Concepts and Fundamentals"},"sidebar":"tutorialSidebar","previous":{"title":"The Robotic Nervous System (ROS 2) Overview","permalink":"/docs/ros-2-fundamentals/ros-2-overview"},"next":{"title":"The Digital Twin (Gazebo & Unity) Overview","permalink":"/docs/digital-twin/digital-twin-overview"}},{"id":"ros-2-fundamentals/ros-2-overview","title":"The Robotic Nervous System (ROS 2) Overview","description":"This module introduces ROS 2 (Robot Operating System 2), the essential middleware for modern robotics. It covers core concepts like nodes, topics, services, and actions, and delves into how ROS 2 facilitates seamless communication and control for complex Physical AI and humanoid robot systems.","source":"@site/docs/ros-2-fundamentals/ros-2-overview.md","sourceDirName":"ros-2-fundamentals","slug":"/ros-2-fundamentals/ros-2-overview","permalink":"/docs/ros-2-fundamentals/ros-2-overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"The Robotic Nervous System (ROS 2) Overview"},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/docs/introduction/"},"next":{"title":"ROS 2 Core Concepts and Fundamentals","permalink":"/docs/ros-2-fundamentals/ros-2-concepts"}},{"id":"vla-and-conversational-robotics/humanoid-robot-development","title":"Humanoid Robot Development and Conversational AI","description":"Humanoid Robot Development focuses on engineering robots that mimic human form and capabilities, tackling challenges like bipedal locomotion, advanced manipulation, and intuitive human-robot interaction. Conversational AI, through technologies like natural language processing and generation, enables these robots to understand and respond to human language, bridging the gap between physical action and intelligent dialogue. This section explores the convergence of these fields.","source":"@site/docs/vla-and-conversational-robotics/humanoid-robot-development.md","sourceDirName":"vla-and-conversational-robotics","slug":"/vla-and-conversational-robotics/humanoid-robot-development","permalink":"/docs/vla-and-conversational-robotics/humanoid-robot-development","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Humanoid Robot Development and Conversational AI"},"sidebar":"tutorialSidebar","previous":{"title":"Vision-Language-Action (VLA) Overview","permalink":"/docs/vla-and-conversational-robotics/vla-overview"},"next":{"title":"Weekly Breakdown","permalink":"/docs/weekly-breakdown"}},{"id":"vla-and-conversational-robotics/vla-overview","title":"Vision-Language-Action (VLA) Overview","description":"Discover Vision-Language-Action (VLA) models and the exciting convergence of large language models (LLMs) with robotics. This module explores how robots can perceive their environment (vision), understand human instructions (language), and translate these into meaningful physical actions, enabling intuitive human-robot interaction and sophisticated autonomous behaviors.","source":"@site/docs/vla-and-conversational-robotics/vla-overview.md","sourceDirName":"vla-and-conversational-robotics","slug":"/vla-and-conversational-robotics/vla-overview","permalink":"/docs/vla-and-conversational-robotics/vla-overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Vision-Language-Action (VLA) Overview"},"sidebar":"tutorialSidebar","previous":{"title":"NVIDIA Isaac Platform for Perception and Training","permalink":"/docs/nvidia-isaac-platform/isaac-perception-training"},"next":{"title":"Humanoid Robot Development and Conversational AI","permalink":"/docs/vla-and-conversational-robotics/humanoid-robot-development"}},{"id":"weekly-breakdown","title":"Weekly Breakdown","description":"This section outlines the suggested weekly progression through the course material, designed to provide a structured learning path for mastering Physical AI and humanoid robotics. Each week builds upon the knowledge and skills acquired in previous weeks, culminating in a comprehensive understanding and practical application of the concepts.","source":"@site/docs/weekly-breakdown.md","sourceDirName":".","slug":"/weekly-breakdown","permalink":"/docs/weekly-breakdown","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Humanoid Robot Development and Conversational AI","permalink":"/docs/vla-and-conversational-robotics/humanoid-robot-development"},"next":{"title":"Assessments","permalink":"/docs/assessments"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"preface"},{"type":"doc","id":"introduction/index","label":"Introduction","translatable":true},{"type":"category","label":"Module 1: ROS 2 Fundamentals","link":{"type":"doc","id":"ros-2-fundamentals/ros-2-overview"},"items":[{"type":"doc","id":"ros-2-fundamentals/ros-2-concepts"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin","link":{"type":"doc","id":"digital-twin/digital-twin-overview"},"items":[{"type":"doc","id":"digital-twin/simulation-with-gazebo"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: NVIDIA Isaac Platform","link":{"type":"doc","id":"nvidia-isaac-platform/isaac-overview"},"items":[{"type":"doc","id":"nvidia-isaac-platform/isaac-perception-training"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: VLA and Conversational Robotics","link":{"type":"doc","id":"vla-and-conversational-robotics/vla-overview"},"items":[{"type":"doc","id":"vla-and-conversational-robotics/humanoid-robot-development"}],"collapsed":true,"collapsible":true},{"type":"doc","id":"weekly-breakdown"},{"type":"doc","id":"assessments"},{"type":"category","label":"Hardware Requirements","link":{"type":"doc","id":"hardware-requirements/index"},"items":[{"type":"doc","id":"hardware-requirements/index"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[{"id":"welcome","metadata":{"permalink":"/blog/welcome","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/blog/tags/facebook","description":"Facebook tag description"},{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.56,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["slorber","yangshun"],"tags":["facebook","hello","docusaurus"]},"unlisted":false,"nextItem":{"title":"MDX Blog Post","permalink":"/blog/mdx-blog-post"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\n\nHere are a few tips you might find useful.\n\n<!-- truncate -->\n\nSimply add Markdown files (or folders) to the `blog` directory.\n\nRegular blog authors can be added to `authors.yml`.\n\nThe blog post date can be extracted from filenames, such as:\n\n- `2019-05-30-welcome.md`\n- `2019-05-30-welcome/index.md`\n\nA blog post folder can be convenient to co-locate blog post images:\n\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\n\nThe blog supports tags as well!\n\n**And if you don't want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."},{"id":"mdx-blog-post","metadata":{"permalink":"/blog/mdx-blog-post","source":"@site/blog/2021-08-01-mdx-blog-post.mdx","title":"MDX Blog Post","description":"Blog posts support Docusaurus Markdown features, such as MDX.","date":"2021-08-01T00:00:00.000Z","tags":[{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.27,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}],"frontMatter":{"slug":"mdx-blog-post","title":"MDX Blog Post","authors":["slorber"],"tags":["docusaurus"]},"unlisted":false,"prevItem":{"title":"Welcome","permalink":"/blog/welcome"},"nextItem":{"title":"Long Blog Post","permalink":"/blog/long-blog-post"}},"content":"Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\n\n:::tip\n\nUse the power of React to create interactive blog posts.\n\n:::\n\n{/* truncate */}\n\nFor example, use JSX to create an interactive button:\n\n```js\n<button onClick={() => alert('button clicked!')}>Click me!</button>\n```\n\n<button onClick={() => alert('button clicked!')}>Click me!</button>"},{"id":"long-blog-post","metadata":{"permalink":"/blog/long-blog-post","source":"@site/blog/2019-05-29-long-blog-post.md","title":"Long Blog Post","description":"This is the summary of a very long blog post,","date":"2019-05-29T00:00:00.000Z","tags":[{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":2.04,"hasTruncateMarker":true,"authors":[{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"long-blog-post","title":"Long Blog Post","authors":"yangshun","tags":["hello","docusaurus"]},"unlisted":false,"prevItem":{"title":"MDX Blog Post","permalink":"/blog/mdx-blog-post"},"nextItem":{"title":"First Blog Post","permalink":"/blog/first-blog-post"}},"content":"This is the summary of a very long blog post,\n\nUse a `<!--` `truncate` `-->` comment to limit blog post size in the list view.\n\n<!-- truncate -->\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"},{"id":"first-blog-post","metadata":{"permalink":"/blog/first-blog-post","source":"@site/blog/2019-05-28-first-blog-post.md","title":"First Blog Post","description":"Lorem ipsum dolor sit amet...","date":"2019-05-28T00:00:00.000Z","tags":[{"inline":false,"label":"Hola","permalink":"/blog/tags/hola","description":"Hola tag description"},{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.13,"hasTruncateMarker":true,"authors":[{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"first-blog-post","title":"First Blog Post","authors":["slorber","yangshun"],"tags":["hola","docusaurus"]},"unlisted":false,"prevItem":{"title":"Long Blog Post","permalink":"/blog/long-blog-post"}},"content":"Lorem ipsum dolor sit amet...\n\n<!-- truncate -->\n\n...consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"}],"blogListPaginated":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/blog","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"blogTags":{"/blog/tags/facebook":{"inline":false,"label":"Facebook","permalink":"/blog/tags/facebook","description":"Facebook tag description","items":["welcome"],"pages":[{"items":["welcome"],"metadata":{"permalink":"/blog/tags/facebook","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/hello":{"inline":false,"label":"Hello","permalink":"/blog/tags/hello","description":"Hello tag description","items":["welcome","long-blog-post"],"pages":[{"items":["welcome","long-blog-post"],"metadata":{"permalink":"/blog/tags/hello","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/docusaurus":{"inline":false,"label":"Docusaurus","permalink":"/blog/tags/docusaurus","description":"Docusaurus tag description","items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"pages":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/blog/tags/docusaurus","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/blog/tags/hola":{"inline":false,"label":"Hola","permalink":"/blog/tags/hola","description":"Hola tag description","items":["first-blog-post"],"pages":[{"items":["first-blog-post"],"metadata":{"permalink":"/blog/tags/hola","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false}},"blogTagsListPath":"/blog/tags","authorsMap":{"yangshun":{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"},"slorber":{"name":"Sébastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}}}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/chat","source":"@site/src/pages/chat.tsx"},{"type":"jsx","permalink":"/","source":"@site/src/pages/index.tsx"},{"type":"mdx","permalink":"/markdown-page","source":"@site/src/pages/markdown-page.md","title":"Markdown page example","description":"You don't need React to write simple standalone pages.","frontMatter":{"title":"Markdown page example"},"unlisted":false}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}