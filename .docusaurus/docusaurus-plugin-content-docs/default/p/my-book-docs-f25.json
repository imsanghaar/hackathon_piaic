{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/my-book/docs/introduction/","label":"Introduction","docId":"introduction/index","unlisted":false},{"type":"category","label":"ROS 2 Fundamentals","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/my-book/docs/ros-2-fundamentals/ros-2-overview","label":"The Robotic Nervous System (ROS 2) Overview","docId":"ros-2-fundamentals/ros-2-overview","unlisted":false},{"type":"link","href":"/my-book/docs/ros-2-fundamentals/ros-2-concepts","label":"ROS 2 Core Concepts and Fundamentals","docId":"ros-2-fundamentals/ros-2-concepts","unlisted":false}]},{"type":"category","label":"The Digital Twin","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/my-book/docs/digital-twin/digital-twin-overview","label":"The Digital Twin (Gazebo & Unity) Overview","docId":"digital-twin/digital-twin-overview","unlisted":false},{"type":"link","href":"/my-book/docs/digital-twin/simulation-with-gazebo","label":"Robot Simulation with Gazebo and Unity","docId":"digital-twin/simulation-with-gazebo","unlisted":false}]},{"type":"category","label":"NVIDIA Isaac Platform","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/my-book/docs/nvidia-isaac-platform/isaac-overview","label":"The AI-Robot Brain (NVIDIA Isaac™) Overview","docId":"nvidia-isaac-platform/isaac-overview","unlisted":false},{"type":"link","href":"/my-book/docs/nvidia-isaac-platform/isaac-perception-training","label":"NVIDIA Isaac Platform for Perception and Training","docId":"nvidia-isaac-platform/isaac-perception-training","unlisted":false}]},{"type":"category","label":"VLA & Conversational Robotics","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/my-book/docs/vla-and-conversational-robotics/vla-overview","label":"Vision-Language-Action (VLA) Overview","docId":"vla-and-conversational-robotics/vla-overview","unlisted":false},{"type":"link","href":"/my-book/docs/vla-and-conversational-robotics/humanoid-robot-development","label":"Humanoid Robot Development and Conversational AI","docId":"vla-and-conversational-robotics/humanoid-robot-development","unlisted":false}]},{"type":"link","href":"/my-book/docs/hardware-requirements/","label":"Hardware Requirements","docId":"hardware-requirements/index","unlisted":false}]},"docs":{"digital-twin/digital-twin-overview":{"id":"digital-twin/digital-twin-overview","title":"The Digital Twin (Gazebo & Unity) Overview","description":"In the realm of Physical AI and robotics, developing and testing complex systems directly on hardware can be time-consuming, expensive, and even dangerous. This is where the concept of a \"Digital Twin\" becomes indispensable. A digital twin is a virtual replica of a physical system, allowing for realistic simulation and experimentation in a safe, controlled environment. This module explores how Gazebo and Unity, two powerful simulation platforms, are utilized to create and interact with digital twins of humanoid robots and their environments.","sidebar":"tutorialSidebar"},"digital-twin/simulation-with-gazebo":{"id":"digital-twin/simulation-with-gazebo","title":"Robot Simulation with Gazebo and Unity","description":"This section delves into the practical aspects of setting up and utilizing simulation environments, specifically focusing on Gazebo for its robust physics capabilities and Unity for its advanced rendering and interactive potential. These tools are critical for iteratively designing, testing, and refining robotic systems without the constraints and risks associated with physical hardware.","sidebar":"tutorialSidebar"},"hardware-requirements/index":{"id":"hardware-requirements/index","title":"Hardware Requirements for Physical AI & Humanoid Robotics","description":"This course, focused on Physical AI and Humanoid Robotics, is inherently technically demanding. It navigates the complex intersection of several computationally intensive domains: physics simulation, visual perception, and generative AI. To effectively engage with the material and successfully complete the capstone projects, students require access to specific hardware configurations. This chapter details the essential hardware components and considerations for building a capable Physical AI laboratory, ranging from individual workstations to specialized robot platforms.","sidebar":"tutorialSidebar"},"introduction/index":{"id":"introduction/index","title":"The Rise of Physical AI and Humanoid Robotics","description":"Why Physical AI Matters","sidebar":"tutorialSidebar"},"nvidia-isaac-platform/isaac-overview":{"id":"nvidia-isaac-platform/isaac-overview","title":"The AI-Robot Brain (NVIDIA Isaac™) Overview","description":"The NVIDIA Isaac platform is a comprehensive suite of hardware, software, and tools designed to accelerate the development and deployment of AI-powered robots, particularly for complex scenarios like humanoid robotics. It serves as the \"brain\" for intelligent machines, enabling advanced perception, simulation, and autonomous capabilities. This module explores the key components of the Isaac platform and their role in bringing Physical AI to life.","sidebar":"tutorialSidebar"},"nvidia-isaac-platform/isaac-perception-training":{"id":"nvidia-isaac-platform/isaac-perception-training","title":"NVIDIA Isaac Platform for Perception and Training","description":"Building upon the overview, this section delves deeper into the practical application of the NVIDIA Isaac platform, focusing on how its components facilitate advanced perception capabilities and robust AI model training for humanoid robots. These weeks provide hands-on experience with the tools that enable robots to understand and interact with their environment intelligently.","sidebar":"tutorialSidebar"},"ros-2-fundamentals/ros-2-concepts":{"id":"ros-2-fundamentals/ros-2-concepts","title":"ROS 2 Core Concepts and Fundamentals","description":"Weeks 3-5: Deep Dive into ROS 2 Fundamentals","sidebar":"tutorialSidebar"},"ros-2-fundamentals/ros-2-overview":{"id":"ros-2-fundamentals/ros-2-overview","title":"The Robotic Nervous System (ROS 2) Overview","description":"The Robot Operating System (ROS) has become the de facto standard middleware for roboticists, providing a flexible framework for writing robot software. ROS 2, the successor, brings significant improvements in real-time capabilities, security, and multi-robot support, making it ideal for complex Physical AI and Humanoid Robotics applications. This module introduces the core components of ROS 2 and how they facilitate sophisticated robot control.","sidebar":"tutorialSidebar"},"vla-and-conversational-robotics/humanoid-robot-development":{"id":"vla-and-conversational-robotics/humanoid-robot-development","title":"Humanoid Robot Development and Conversational AI","description":"Weeks 11-12: Advanced Humanoid Robot Development","sidebar":"tutorialSidebar"},"vla-and-conversational-robotics/vla-overview":{"id":"vla-and-conversational-robotics/vla-overview","title":"Vision-Language-Action (VLA) Overview","description":"The frontier of Physical AI is increasingly defined by the integration of large language models (LLMs) with robotic systems, giving rise to \"Vision-Language-Action\" (VLA) models. This represents a powerful convergence where robots can not only perceive their environment (vision) and understand human instructions (language) but also translate these into meaningful physical actions. This module explores how LLMs are transforming robotic capabilities, enabling more intuitive human-robot interaction and sophisticated autonomous behaviors.","sidebar":"tutorialSidebar"}}}}