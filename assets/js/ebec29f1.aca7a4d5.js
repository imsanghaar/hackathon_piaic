"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[3346],{2452:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"typescript-ai-development","title":"Chapter 14 - TypeScript for AI Development","description":"Building AI applications with TypeScript - frameworks, best practices, and the future","source":"@site/docs/14-typescript-ai-development.md","sourceDirName":".","slug":"/typescript-ai-development","permalink":"/hackathon_piaic/docs/typescript-ai-development","draft":false,"unlisted":false,"editUrl":"https://github.com/imsanghaar/piaic_hackathon_ai/edit/main/docs/14-typescript-ai-development.md","tags":[],"version":"current","sidebarPosition":14,"frontMatter":{"sidebar_position":14,"title":"Chapter 14 - TypeScript for AI Development","description":"Building AI applications with TypeScript - frameworks, best practices, and the future"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 13 - Python for AI Development","permalink":"/hackathon_piaic/docs/python-ai-development"},"next":{"title":"Chapter 15 - AI Trends 2025","permalink":"/hackathon_piaic/docs/ai-trends-2025"}}');var s=r(4848),i=r(8453);const o={sidebar_position:14,title:"Chapter 14 - TypeScript for AI Development",description:"Building AI applications with TypeScript - frameworks, best practices, and the future"},a="Chapter 14: TypeScript for AI Development",c={},l=[{value:"14.1 The TypeScript AI Revolution",id:"141-the-typescript-ai-revolution",level:2},{value:"Why TypeScript for AI?",id:"why-typescript-for-ai",level:3},{value:"TypeScript vs Python for AI",id:"typescript-vs-python-for-ai",level:3},{value:"14.2 Essential TypeScript AI Frameworks",id:"142-essential-typescript-ai-frameworks",level:2},{value:"LangChain.js - AI Agent Development",id:"langchainjs---ai-agent-development",level:3},{value:"Advanced LangChain Workflows",id:"advanced-langchain-workflows",level:3},{value:"Vercel AI SDK - Modern Web AI",id:"vercel-ai-sdk---modern-web-ai",level:3},{value:"React Integration",id:"react-integration",level:4},{value:"Structured Object Generation",id:"structured-object-generation",level:4},{value:"VoltAgent - TypeScript-First AI Agents",id:"voltagent---typescript-first-ai-agents",level:3},{value:"Visual Debugging",id:"visual-debugging",level:4},{value:"14.3 Machine Learning in TypeScript",id:"143-machine-learning-in-typescript",level:2},{value:"TensorFlow.js",id:"tensorflowjs",level:3},{value:"Image Classification",id:"image-classification",level:3},{value:"Transfer Learning",id:"transfer-learning",level:3},{value:"14.4 Building Production AI Applications",id:"144-building-production-ai-applications",level:2},{value:"Type-Safe AI API with tRPC",id:"type-safe-ai-api-with-trpc",level:3},{value:"Type-Safe Client",id:"type-safe-client",level:3},{value:"Real-Time AI Streaming",id:"real-time-ai-streaming",level:3},{value:"Client-Side Streaming",id:"client-side-streaming",level:3},{value:"14.5 Multi-Agent Systems",id:"145-multi-agent-systems",level:2},{value:"Agent Orchestration with Mastra",id:"agent-orchestration-with-mastra",level:3},{value:"AWS Multi-Agent Orchestrator",id:"aws-multi-agent-orchestrator",level:3},{value:"14.6 Best Practices",id:"146-best-practices",level:2},{value:"Strong Typing for AI",id:"strong-typing-for-ai",level:3},{value:"Error Handling",id:"error-handling",level:3},{value:"Testing AI Applications",id:"testing-ai-applications",level:3},{value:"What&#39;s Next?",id:"whats-next",level:2}];function p(e){const n={admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"chapter-14-typescript-for-ai-development",children:"Chapter 14: TypeScript for AI Development"})}),"\n",(0,s.jsxs)(n.p,{children:["TypeScript has emerged as a powerhouse for AI development in 2025, surpassing Python and JavaScript to become ",(0,s.jsx)(n.strong,{children:"the most used language on GitHub"})," in August 2025. This chapter explores why TypeScript is revolutionizing AI application development and how to leverage it effectively."]}),"\n",(0,s.jsx)(n.h2,{id:"141-the-typescript-ai-revolution",children:"14.1 The TypeScript AI Revolution"}),"\n",(0,s.jsx)(n.h3,{id:"why-typescript-for-ai",children:"Why TypeScript for AI?"}),"\n",(0,s.jsx)(n.admonition,{title:"Historic Milestone",type:"tip",children:(0,s.jsx)(n.p,{children:"In August 2025, TypeScript became the #1 language on GitHub, reflecting a shift towards typed languages for more reliable AI-assisted coding."})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Advantages:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type Safety"}),": Catch bugs at compile-time, not runtime"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scalability"}),": Enterprise-grade applications with confidence"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Full-Stack Unity"}),": Same language for frontend and backend"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"AI Assistant Friendly"}),": Better code generation and inference"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Rich Ecosystem"}),": Growing collection of AI/ML libraries"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"typescript-vs-python-for-ai",children:"TypeScript vs Python for AI"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Aspect"}),(0,s.jsx)(n.th,{children:"TypeScript"}),(0,s.jsx)(n.th,{children:"Python"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Type Safety"})}),(0,s.jsx)(n.td,{children:"\u2705 Built-in"}),(0,s.jsx)(n.td,{children:"\ud83d\udfe1 Optional (mypy)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Web Integration"})}),(0,s.jsx)(n.td,{children:"\u2705 Native"}),(0,s.jsx)(n.td,{children:"\ud83d\udfe1 Requires bridges"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Performance"})}),(0,s.jsx)(n.td,{children:"\u2705 Faster (V8/JIT)"}),(0,s.jsx)(n.td,{children:"\ud83d\udfe1 Slower (interpreted)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"ML Libraries"})}),(0,s.jsx)(n.td,{children:"\ud83d\udfe1 Growing"}),(0,s.jsx)(n.td,{children:"\u2705 Comprehensive"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Real-time Apps"})}),(0,s.jsx)(n.td,{children:"\u2705 Excellent (Node.js)"}),(0,s.jsx)(n.td,{children:"\ud83d\udfe1 Limited"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Deployment"})}),(0,s.jsx)(n.td,{children:"\u2705 Easy (serverless)"}),(0,s.jsx)(n.td,{children:"\u2705 Good"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"142-essential-typescript-ai-frameworks",children:"14.2 Essential TypeScript AI Frameworks"}),"\n",(0,s.jsx)(n.h3,{id:"langchainjs---ai-agent-development",children:"LangChain.js - AI Agent Development"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { OpenAI } from "langchain/llms/openai";\r\nimport { PromptTemplate } from "langchain/prompts";\r\nimport { LLMChain } from "langchain/chains";\r\nimport { BufferMemory } from "langchain/memory";\r\n\r\n// Create prompt template\r\nconst template = `\r\nYou are an expert TypeScript developer.\r\nQuestion: {question}\r\nProvide a detailed answer with code examples.\r\n`;\r\n\r\nconst prompt = new PromptTemplate({\r\n  template,\r\n  inputVariables: ["question"],\r\n});\r\n\r\n// Initialize LLM\r\nconst llm = new OpenAI({\r\n  temperature: 0.7,\r\n  modelName: "gpt-4",\r\n});\r\n\r\n// Create chain\r\nconst chain = new LLMChain({\r\n  llm,\r\n  prompt,\r\n  memory: new BufferMemory(),\r\n});\r\n\r\n// Execute\r\nconst response = await chain.call({\r\n  question: "How do I implement a binary tree in TypeScript?",\r\n});\r\n\r\nconsole.log(response.text);\n'})}),"\n",(0,s.jsx)(n.h3,{id:"advanced-langchain-workflows",children:"Advanced LangChain Workflows"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { ChatOpenAI } from "langchain/chat_models/openai";\r\nimport { StructuredOutputParser } from "langchain/output_parsers";\r\nimport { RunnableSequence } from "langchain/schema/runnable";\r\nimport { z } from "zod";\r\n\r\n// Define structured output schema\r\nconst schema = z.object({\r\n  sentiment: z.enum(["positive", "negative", "neutral"]),\r\n  confidence: z.number().min(0).max(1),\r\n  keywords: z.array(z.string()),\r\n  summary: z.string(),\r\n});\r\n\r\nconst parser = StructuredOutputParser.fromZodSchema(schema);\r\n\r\n// Create analysis chain\r\nconst analysisChain = RunnableSequence.from([\r\n  {\r\n    input: (text: string) => text,\r\n    format_instructions: () => parser.getFormatInstructions(),\r\n  },\r\n  new ChatOpenAI({ temperature: 0.1 }),\r\n  parser,\r\n]);\r\n\r\n// Analyze text\r\nconst result = await analysisChain.invoke(\r\n  "This product exceeded my expectations! The quality is outstanding."\r\n);\r\n\r\n// Fully typed result!\r\nconsole.log(result.sentiment); // "positive"\r\nconsole.log(result.confidence); // 0.95\r\nconsole.log(result.keywords); // ["exceeded", "expectations", "outstanding"]\n'})}),"\n",(0,s.jsx)(n.h3,{id:"vercel-ai-sdk---modern-web-ai",children:"Vercel AI SDK - Modern Web AI"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { openai } from "@ai-sdk/openai";\r\nimport { streamText } from "ai";\r\n\r\n// Stream AI responses in real-time\r\nexport async function POST(req: Request) {\r\n  const { messages } = await req.json();\r\n\r\n  const result = await streamText({\r\n    model: openai("gpt-4"),\r\n    messages,\r\n    system: "You are a helpful coding assistant.",\r\n  });\r\n\r\n  return result.toAIStreamResponse();\r\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"react-integration",children:"React Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:'"use client";\r\n\r\nimport { useChat } from "ai/react";\r\n\r\nexport default function Chat() {\r\n  const { messages, input, handleInputChange, handleSubmit, isLoading } =\r\n    useChat({\r\n      api: "/api/chat",\r\n    });\r\n\r\n  return (\r\n    <div className="chat-container">\r\n      <div className="messages">\r\n        {messages.map((message) => (\r\n          <div key={message.id} className={`message ${message.role}`}>\r\n            <p>{message.content}</p>\r\n          </div>\r\n        ))}\r\n        {isLoading && <div className="loading">AI is thinking...</div>}\r\n      </div>\r\n\r\n      <form onSubmit={handleSubmit}>\r\n        <input\r\n          value={input}\r\n          onChange={handleInputChange}\r\n          placeholder="Ask anything..."\r\n          disabled={isLoading}\r\n        />\r\n        <button type="submit" disabled={isLoading}>\r\n          Send\r\n        </button>\r\n      </form>\r\n    </div>\r\n  );\r\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"structured-object-generation",children:"Structured Object Generation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { openai } from "@ai-sdk/openai";\r\nimport { generateObject } from "ai";\r\nimport { z } from "zod";\r\n\r\n// Define schema\r\nconst recipeSchema = z.object({\r\n  name: z.string(),\r\n  ingredients: z.array(\r\n    z.object({\r\n      name: z.string(),\r\n      amount: z.string(),\r\n    })\r\n  ),\r\n  steps: z.array(z.string()),\r\n  prepTime: z.number(),\r\n  cookTime: z.number(),\r\n  servings: z.number(),\r\n});\r\n\r\n// Generate structured data\r\nconst { object: recipe } = await generateObject({\r\n  model: openai("gpt-4"),\r\n  schema: recipeSchema,\r\n  prompt: "Generate a recipe for chocolate chip cookies",\r\n});\r\n\r\n// Fully typed recipe object!\r\nconsole.log(recipe.name); // string\r\nconsole.log(recipe.ingredients); // Array<{name: string, amount: string}>\r\nconsole.log(recipe.prepTime); // number\n'})}),"\n",(0,s.jsx)(n.h3,{id:"voltagent---typescript-first-ai-agents",children:"VoltAgent - TypeScript-First AI Agents"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { VoltAgent, Tool, Memory } from "voltagent";\r\n\r\n// Define custom tool\r\nconst weatherTool: Tool = {\r\n  name: "get_weather",\r\n  description: "Get current weather for a city",\r\n  parameters: {\r\n    city: { type: "string", required: true },\r\n  },\r\n  execute: async ({ city }: { city: string }) => {\r\n    const response = await fetch(\r\n      `https://api.weather.com/v1/${city}`\r\n    );\r\n    return response.json();\r\n  },\r\n};\r\n\r\n// Create agent with tools and memory\r\nconst agent = new VoltAgent({\r\n  model: "gpt-4",\r\n  tools: [weatherTool],\r\n  memory: new Memory({ window: 10 }),\r\n  systemPrompt: "You are a helpful travel assistant.",\r\n});\r\n\r\n// Execute task\r\nconst result = await agent.execute(\r\n  "What\'s the weather like in Tokyo? Should I bring an umbrella?"\r\n);\r\n\r\nconsole.log(result.response);\r\nconsole.log(result.toolCalls); // Track which tools were used\r\nconsole.log(result.reasoning); // See agent\'s decision process\n'})}),"\n",(0,s.jsx)(n.h4,{id:"visual-debugging",children:"Visual Debugging"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'// VoltAgent includes a debugging console\r\nimport { DebugConsole } from "voltagent/debug";\r\n\r\nconst console = new DebugConsole(agent);\r\n\r\n// Watch agent execution step-by-step\r\nawait console.watch(async () => {\r\n  await agent.execute("Complex multi-step task");\r\n});\r\n\r\n// Output shows:\r\n// 1. Initial thought process\r\n// 2. Tool selections\r\n// 3. Intermediate results\r\n// 4. Final synthesis\r\n// 5. Memory updates\n'})}),"\n",(0,s.jsx)(n.h2,{id:"143-machine-learning-in-typescript",children:"14.3 Machine Learning in TypeScript"}),"\n",(0,s.jsx)(n.h3,{id:"tensorflowjs",children:"TensorFlow.js"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import * as tf from "@tensorflow/tfjs";\r\n\r\n// Define and train a model\r\nconst model = tf.sequential({\r\n  layers: [\r\n    tf.layers.dense({ inputShape: [8], units: 16, activation: "relu" }),\r\n    tf.layers.dropout({ rate: 0.2 }),\r\n    tf.layers.dense({ units: 8, activation: "relu" }),\r\n    tf.layers.dense({ units: 1, activation: "sigmoid" }),\r\n  ],\r\n});\r\n\r\n// Compile model\r\nmodel.compile({\r\n  optimizer: tf.train.adam(0.001),\r\n  loss: "binaryCrossentropy",\r\n  metrics: ["accuracy"],\r\n});\r\n\r\n// Train model\r\nconst xs = tf.randomNormal([100, 8]);\r\nconst ys = tf.randomUniform([100, 1]);\r\n\r\nawait model.fit(xs, ys, {\r\n  epochs: 50,\r\n  batchSize: 32,\r\n  validationSplit: 0.2,\r\n  callbacks: {\r\n    onEpochEnd: (epoch, logs) => {\r\n      console.log(`Epoch ${epoch}: loss = ${logs?.loss}`);\r\n    },\r\n  },\r\n});\r\n\r\n// Make predictions\r\nconst predictions = model.predict(tf.randomNormal([1, 8])) as tf.Tensor;\r\npredictions.print();\n'})}),"\n",(0,s.jsx)(n.h3,{id:"image-classification",children:"Image Classification"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import * as mobilenet from "@tensorflow-models/mobilenet";\r\n\r\n// Load pre-trained model\r\nconst model = await mobilenet.load();\r\n\r\n// Classify image\r\nconst img = document.getElementById("image") as HTMLImageElement;\r\nconst predictions = await model.classify(img);\r\n\r\n// Type-safe results\r\npredictions.forEach((prediction) => {\r\n  console.log(`${prediction.className}: ${prediction.probability * 100}%`);\r\n});\n'})}),"\n",(0,s.jsx)(n.h3,{id:"transfer-learning",children:"Transfer Learning"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import * as tf from "@tensorflow/tfjs";\r\nimport * as mobilenet from "@tensorflow-models/mobilenet";\r\n\r\nasync function createCustomClassifier() {\r\n  // Load pre-trained MobileNet\r\n  const baseModel = await mobilenet.load();\r\n\r\n  // Create new model for custom classification\r\n  const model = tf.sequential({\r\n    layers: [\r\n      // Freeze base layers (use pre-trained weights)\r\n      tf.layers.dense({\r\n        inputShape: [1024], // MobileNet feature vector\r\n        units: 128,\r\n        activation: "relu",\r\n        trainable: false,\r\n      }),\r\n      // Custom trainable layers\r\n      tf.layers.dropout({ rate: 0.3 }),\r\n      tf.layers.dense({ units: 10, activation: "softmax" }), // 10 classes\r\n    ],\r\n  });\r\n\r\n  model.compile({\r\n    optimizer: "adam",\r\n    loss: "categoricalCrossentropy",\r\n    metrics: ["accuracy"],\r\n  });\r\n\r\n  return { baseModel, classifier: model };\r\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"144-building-production-ai-applications",children:"14.4 Building Production AI Applications"}),"\n",(0,s.jsx)(n.h3,{id:"type-safe-ai-api-with-trpc",children:"Type-Safe AI API with tRPC"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'// server/router.ts\r\nimport { initTRPC } from "@trpc/server";\r\nimport { z } from "zod";\r\nimport { OpenAI } from "openai";\r\n\r\nconst t = initTRPC.create();\r\nconst openai = new OpenAI();\r\n\r\nexport const appRouter = t.router({\r\n  chat: t.procedure\r\n    .input(\r\n      z.object({\r\n        message: z.string().min(1).max(1000),\r\n        conversationId: z.string().optional(),\r\n      })\r\n    )\r\n    .output(\r\n      z.object({\r\n        response: z.string(),\r\n        conversationId: z.string(),\r\n        tokensUsed: z.number(),\r\n      })\r\n    )\r\n    .mutation(async ({ input }) => {\r\n      const completion = await openai.chat.completions.create({\r\n        model: "gpt-4",\r\n        messages: [{ role: "user", content: input.message }],\r\n      });\r\n\r\n      return {\r\n        response: completion.choices[0].message.content ?? "",\r\n        conversationId: input.conversationId ?? crypto.randomUUID(),\r\n        tokensUsed: completion.usage?.total_tokens ?? 0,\r\n      };\r\n    }),\r\n\r\n  generateImage: t.procedure\r\n    .input(\r\n      z.object({\r\n        prompt: z.string(),\r\n        size: z.enum(["256x256", "512x512", "1024x1024"]),\r\n      })\r\n    )\r\n    .mutation(async ({ input }) => {\r\n      const response = await openai.images.generate({\r\n        prompt: input.prompt,\r\n        size: input.size,\r\n        n: 1,\r\n      });\r\n\r\n      return {\r\n        url: response.data[0].url,\r\n      };\r\n    }),\r\n});\r\n\r\nexport type AppRouter = typeof appRouter;\n'})}),"\n",(0,s.jsx)(n.h3,{id:"type-safe-client",children:"Type-Safe Client"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'// client/index.ts\r\nimport { createTRPCProxyClient, httpBatchLink } from "@trpc/client";\r\nimport type { AppRouter } from "../server/router";\r\n\r\nconst client = createTRPCProxyClient<AppRouter>({\r\n  links: [\r\n    httpBatchLink({\r\n      url: "http://localhost:3000/trpc",\r\n    }),\r\n  ],\r\n});\r\n\r\n// Fully type-safe API calls!\r\nconst result = await client.chat.mutate({\r\n  message: "Explain TypeScript generics",\r\n  conversationId: "abc-123",\r\n});\r\n\r\nconsole.log(result.response); // string\r\nconsole.log(result.tokensUsed); // number\r\n\r\n// TypeScript error if wrong type\r\n// client.chat.mutate({ message: 123 }); // \u274c Error!\n'})}),"\n",(0,s.jsx)(n.h3,{id:"real-time-ai-streaming",children:"Real-Time AI Streaming"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { Server } from "socket.io";\r\nimport { OpenAI } from "openai";\r\n\r\nconst io = new Server(3001, {\r\n  cors: { origin: "*" },\r\n});\r\n\r\nconst openai = new OpenAI();\r\n\r\nio.on("connection", (socket) => {\r\n  console.log("Client connected:", socket.id);\r\n\r\n  socket.on("chat", async (message: string) => {\r\n    try {\r\n      const stream = await openai.chat.completions.create({\r\n        model: "gpt-4",\r\n        messages: [{ role: "user", content: message }],\r\n        stream: true,\r\n      });\r\n\r\n      // Stream tokens to client in real-time\r\n      for await (const chunk of stream) {\r\n        const token = chunk.choices[0]?.delta?.content || "";\r\n        socket.emit("token", token);\r\n      }\r\n\r\n      socket.emit("complete");\r\n    } catch (error) {\r\n      socket.emit("error", error);\r\n    }\r\n  });\r\n});\n'})}),"\n",(0,s.jsx)(n.h3,{id:"client-side-streaming",children:"Client-Side Streaming"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:'import { useEffect, useState } from "react";\r\nimport { io, Socket } from "socket.io-client";\r\n\r\nexport function StreamingChat() {\r\n  const [socket, setSocket] = useState<Socket | null>(null);\r\n  const [response, setResponse] = useState("");\r\n  const [isStreaming, setIsStreaming] = useState(false);\r\n\r\n  useEffect(() => {\r\n    const newSocket = io("http://localhost:3001");\r\n    setSocket(newSocket);\r\n\r\n    newSocket.on("token", (token: string) => {\r\n      setResponse((prev) => prev + token);\r\n    });\r\n\r\n    newSocket.on("complete", () => {\r\n      setIsStreaming(false);\r\n    });\r\n\r\n    return () => {\r\n      newSocket.close();\r\n    };\r\n  }, []);\r\n\r\n  const sendMessage = (message: string) => {\r\n    setResponse("");\r\n    setIsStreaming(true);\r\n    socket?.emit("chat", message);\r\n  };\r\n\r\n  return (\r\n    <div>\r\n      <div className="response">{response}</div>\r\n      {isStreaming && <div className="typing-indicator">AI is typing...</div>}\r\n      <button onClick={() => sendMessage("Hello!")}>Send</button>\r\n    </div>\r\n  );\r\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"145-multi-agent-systems",children:"14.5 Multi-Agent Systems"}),"\n",(0,s.jsx)(n.h3,{id:"agent-orchestration-with-mastra",children:"Agent Orchestration with Mastra"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { Mastra, Agent, Workflow } from "mastra";\r\n\r\n// Define specialized agents\r\nconst codeAgent = new Agent({\r\n  name: "code-generator",\r\n  model: "gpt-4",\r\n  systemPrompt: "You are an expert TypeScript developer.",\r\n  tools: ["file-system", "terminal"],\r\n});\r\n\r\nconst reviewAgent = new Agent({\r\n  name: "code-reviewer",\r\n  model: "claude-sonnet-4.5",\r\n  systemPrompt: "You are a senior code reviewer focused on best practices.",\r\n});\r\n\r\nconst testAgent = new Agent({\r\n  name: "test-generator",\r\n  model: "gpt-4",\r\n  systemPrompt: "You generate comprehensive test suites.",\r\n  tools: ["file-system"],\r\n});\r\n\r\n// Create workflow\r\nconst developmentWorkflow = new Workflow({\r\n  name: "feature-development",\r\n  agents: [codeAgent, reviewAgent, testAgent],\r\n  steps: [\r\n    {\r\n      agent: codeAgent,\r\n      task: "Implement the feature based on requirements",\r\n      output: "code",\r\n    },\r\n    {\r\n      agent: reviewAgent,\r\n      task: "Review the code for issues and improvements",\r\n      input: "code",\r\n      output: "review",\r\n    },\r\n    {\r\n      agent: codeAgent,\r\n      task: "Address review comments",\r\n      input: ["code", "review"],\r\n      output: "revised-code",\r\n    },\r\n    {\r\n      agent: testAgent,\r\n      task: "Generate comprehensive tests",\r\n      input: "revised-code",\r\n      output: "tests",\r\n    },\r\n  ],\r\n});\r\n\r\n// Execute workflow\r\nconst result = await developmentWorkflow.run({\r\n  requirements: "Build a user authentication system with JWT",\r\n});\r\n\r\nconsole.log(result.outputs);\n'})}),"\n",(0,s.jsx)(n.h3,{id:"aws-multi-agent-orchestrator",children:"AWS Multi-Agent Orchestrator"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { MultiAgentOrchestrator, BedrockLLMAgent } from "multi-agent-orchestrator";\r\n\r\nconst orchestrator = new MultiAgentOrchestrator();\r\n\r\n// Add specialized agents\r\norchestrator.addAgent(\r\n  new BedrockLLMAgent({\r\n    name: "customer-support",\r\n    description: "Handles customer support queries",\r\n    modelId: "anthropic.claude-v3",\r\n  })\r\n);\r\n\r\norchestrator.addAgent(\r\n  new BedrockLLMAgent({\r\n    name: "technical-docs",\r\n    description: "Answers technical documentation questions",\r\n    modelId: "anthropic.claude-v3",\r\n  })\r\n);\r\n\r\norchestrator.addAgent(\r\n  new BedrockLLMAgent({\r\n    name: "sales",\r\n    description: "Handles sales and pricing questions",\r\n    modelId: "anthropic.claude-v3",\r\n  })\r\n);\r\n\r\n// Orchestrator automatically routes to the right agent\r\nconst response = await orchestrator.routeRequest(\r\n  "How do I integrate your API with Next.js?",\r\n  "user-123",\r\n  "session-456"\r\n);\r\n\r\nconsole.log(response.output);\r\nconsole.log(`Routed to agent: ${response.agent.name}`);\n'})}),"\n",(0,s.jsx)(n.h2,{id:"146-best-practices",children:"14.6 Best Practices"}),"\n",(0,s.jsx)(n.h3,{id:"strong-typing-for-ai",children:"Strong Typing for AI"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'// Define strict types for AI interactions\r\ninterface ChatMessage {\r\n  role: "system" | "user" | "assistant";\r\n  content: string;\r\n  timestamp: Date;\r\n}\r\n\r\ninterface AICompletionRequest {\r\n  messages: ChatMessage[];\r\n  temperature: number;\r\n  maxTokens: number;\r\n  model: "gpt-4" | "gpt-4-turbo" | "claude-3";\r\n}\r\n\r\ninterface AICompletionResponse {\r\n  content: string;\r\n  tokensUsed: {\r\n    prompt: number;\r\n    completion: number;\r\n    total: number;\r\n  };\r\n  finishReason: "stop" | "length" | "content_filter";\r\n}\r\n\r\n// Type-safe AI service\r\nclass AIService {\r\n  async complete(request: AICompletionRequest): Promise<AICompletionResponse> {\r\n    // Implementation with full type safety\r\n  }\r\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"error-handling",children:"Error Handling"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { z } from "zod";\r\n\r\n// Define error types\r\nclass AIServiceError extends Error {\r\n  constructor(\r\n    message: string,\r\n    public code: "rate_limit" | "invalid_request" | "model_error",\r\n    public details?: unknown\r\n  ) {\r\n    super(message);\r\n  }\r\n}\r\n\r\n// Robust error handling\r\nasync function safeLLMCall(prompt: string): Promise<string> {\r\n  try {\r\n    const response = await openai.chat.completions.create({\r\n      model: "gpt-4",\r\n      messages: [{ role: "user", content: prompt }],\r\n    });\r\n\r\n    // Validate response\r\n    const content = response.choices[0]?.message?.content;\r\n    if (!content) {\r\n      throw new AIServiceError("Empty response from AI", "model_error");\r\n    }\r\n\r\n    return content;\r\n  } catch (error) {\r\n    if (error instanceof OpenAI.APIError) {\r\n      if (error.status === 429) {\r\n        throw new AIServiceError("Rate limit exceeded", "rate_limit", error);\r\n      }\r\n    }\r\n\r\n    throw new AIServiceError("Unexpected error", "model_error", error);\r\n  }\r\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"testing-ai-applications",children:"Testing AI Applications"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { describe, it, expect, vi } from "vitest";\r\n\r\ndescribe("AI Chat Service", () => {\r\n  it("should generate valid responses", async () => {\r\n    const mockOpenAI = {\r\n      chat: {\r\n        completions: {\r\n          create: vi.fn().mockResolvedValue({\r\n            choices: [\r\n              {\r\n                message: { content: "Mock AI response" },\r\n              },\r\n            ],\r\n          }),\r\n        },\r\n      },\r\n    };\r\n\r\n    const service = new AIService(mockOpenAI as any);\r\n    const response = await service.chat("Hello");\r\n\r\n    expect(response).toBe("Mock AI response");\r\n    expect(mockOpenAI.chat.completions.create).toHaveBeenCalledWith(\r\n      expect.objectContaining({\r\n        model: "gpt-4",\r\n        messages: [{ role: "user", content: "Hello" }],\r\n      })\r\n    );\r\n  });\r\n\r\n  it("should handle rate limiting", async () => {\r\n    const mockOpenAI = {\r\n      chat: {\r\n        completions: {\r\n          create: vi.fn().mockRejectedValue(\r\n            new OpenAI.APIError("Rate limit", { status: 429 })\r\n          ),\r\n        },\r\n      },\r\n    };\r\n\r\n    const service = new AIService(mockOpenAI as any);\r\n\r\n    await expect(service.chat("Hello")).rejects.toThrow(AIServiceError);\r\n  });\r\n});\n'})}),"\n",(0,s.jsx)(n.p,{children:"##Summary"}),"\n",(0,s.jsx)(n.p,{children:"TypeScript is transforming AI development:"}),"\n",(0,s.jsxs)(n.p,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Type Safety"}),": Fewer runtime errors, better developer experience",(0,s.jsx)(n.br,{}),"\n","\u2705 ",(0,s.jsx)(n.strong,{children:"Rich Frameworks"}),": LangChain.js, Vercel AI SDK, VoltAgent",(0,s.jsx)(n.br,{}),"\n","\u2705 ",(0,s.jsx)(n.strong,{children:"Full-Stack"}),": Same language for frontend and backend",(0,s.jsx)(n.br,{}),"\n","\u2705 ",(0,s.jsx)(n.strong,{children:"Growing Ecosystem"}),": Rapidly expanding AI/ML libraries",(0,s.jsx)(n.br,{}),"\n","\u2705 ",(0,s.jsx)(n.strong,{children:"Production Ready"}),": Enterprise-grade applications",(0,s.jsx)(n.br,{}),"\n","\u2705 ",(0,s.jsx)(n.strong,{children:"AI Assistant Friendly"}),": Better code generation"]}),"\n",(0,s.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,s.jsxs)(n.p,{children:["In the next chapter, we'll explore ",(0,s.jsx)(n.strong,{children:"Latest AI Trends 2025"})," - cutting-edge developments from TechCrunch, emerging technologies, and the future of AI in software development."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Takeaways:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"TypeScript is now the #1 language on GitHub"}),"\n",(0,s.jsx)(n.li,{children:"Excellent for AI agents and LLM applications"}),"\n",(0,s.jsx)(n.li,{children:"Full type safety reduces bugs in production"}),"\n",(0,s.jsx)(n.li,{children:"Growing ecosystem of AI/ML frameworks"}),"\n",(0,s.jsx)(n.li,{children:"Perfect for full-stack AI applications"}),"\n",(0,s.jsx)(n.li,{children:"Multi-agent systems are the future"}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var t=r(6540);const s={},i=t.createContext(s);function o(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);